{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b70901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4265b9",
   "metadata": {},
   "source": [
    "# Creating new datasets\n",
    "\n",
    "The goal of this notebook is to make two unified datasets out of the following larger datasets: MMLU, TruthfulQA, HellaSwag. \n",
    "\n",
    "The first CSV should have the following columns: Type, Question, Options, Answer. Question refers to the actual prompt. Type refers to the category of question (math, history, law, fact, hellaswag). Options will be the multiple choice options. Answer will be the correct answer, in 1/2/3/4 format. This dataset will be evaluated using probability scoring each option.\n",
    "\n",
    "The second CSV will be focused on generation quality. This will also be made from TruthfulQA, HellaSwag, etc, but will utilize an LLM-as-a-judge for generation quality estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a00da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a9040",
   "metadata": {},
   "source": [
    "## 1. MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4dc07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clinical = load_dataset(\"cais/mmlu\", \"clinical_knowledge\")['test'].to_pandas()\n",
    "data_law = load_dataset(\"cais/mmlu\", \"international_law\")['test'].to_pandas()\n",
    "data_cs = load_dataset(\"cais/mmlu\", \"college_computer_science\")['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f99080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>subject</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What size of cannula would you use in a patien...</td>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>[18 gauge., 20 gauge., 22 gauge., 24 gauge.]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The key attribute in successful marathon runni...</td>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>[strength., power., stride length., stamina.]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following is the commonest cause ...</td>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>[Alzheimer's disease., Cerebrovascular (stroke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question             subject  \\\n",
       "0  What size of cannula would you use in a patien...  clinical_knowledge   \n",
       "1  The key attribute in successful marathon runni...  clinical_knowledge   \n",
       "2  Which of the following is the commonest cause ...  clinical_knowledge   \n",
       "\n",
       "                                             choices  answer  \n",
       "0       [18 gauge., 20 gauge., 22 gauge., 24 gauge.]       0  \n",
       "1      [strength., power., stride length., stamina.]       3  \n",
       "2  [Alzheimer's disease., Cerebrovascular (stroke...       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clinical.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c48b8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add each of the dataframes to the final dataframe\n",
    "df_final = pd.concat([df_final, data_clinical, data_law, data_cs])\n",
    "\n",
    "# rename the answer column to answer\n",
    "df_final = df_final.rename(columns={'question': 'Question', 'subject': 'Type', 'choices': 'Options', 'answer': 'Answer'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da844638",
   "metadata": {},
   "source": [
    "# 2. TruthfulQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc72a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since EleutherAI/truthful_qa_mc couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'multiple_choice' at /Users/roku/.cache/huggingface/datasets/EleutherAI___truthful_qa_mc/multiple_choice/1.1.0/0e21fda4ea37223e25ab6c4d30e8a4cf2e32f2f1 (last modified on Sun Nov 30 20:46:17 2025).\n"
     ]
    }
   ],
   "source": [
    "data_truth = load_dataset(\"EleutherAI/truthful_qa_mc\")['validation'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3019b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_truth = data_truth.rename(columns={'question': 'Question', 'choices': 'Options', 'label': 'Answer'}, inplace=False)\n",
    "data_truth['Type'] = 'TruthfulQA'\n",
    "\n",
    "df_final = pd.concat([df_final, data_truth])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9fff5",
   "metadata": {},
   "source": [
    "## 3. HellaSwag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913bf385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset of data from hellaswag (only 400 rows)\n",
    "data_hs = load_dataset(\"Rowan/hellaswag\", split=\"train\").to_pandas()[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fba0e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hs = data_hs.rename(columns={'ctx': 'Question', 'endings': 'Options', 'label': 'Answer'}, inplace=False)\n",
    "data_hs['Type'] = 'HellaSwag'\n",
    "data_hs = data_hs[['Question', 'Options', 'Answer', 'Type']]\n",
    "\n",
    "df_final = pd.concat([df_final, data_hs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b2896be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_json(\"data_mc.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f97ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b001e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
